# nginx.conf - Production Reverse Proxy
upstream api_backend {
    server app:8081;
    keepalive 32;
}

server {
    listen 80;
    server_name localhost;
    client_max_body_size 50M;
    
    # Health check endpoint
    location /health {
        proxy_pass http://api_backend/health;
        proxy_set_header Host $host;
        proxy_connect_timeout 5s;
        proxy_read_timeout 10s;
    }
    
    # API endpoints
    location /api/ {
        proxy_pass http://api_backend/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 300s;
        proxy_connect_timeout 60s;
    }
    
    # Serve static reports
    location /reports/ {
        alias /workspace/reports/;
        expires 1d;
        add_header Cache-Control "public, no-transform";
        add_header X-Content-Type-Options nosniff;
    }
    
    # API documentation
    location / {
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}

---
# monitoring/prometheus.yml - Metrics Collection
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'ecg-ppg-api'
    static_configs:
      - targets: ['app:8081']
    metrics_path: '/metrics'
    scrape_interval: 30s
    scrape_timeout: 10s
    
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    metrics_path: '/nginx_status'
    scrape_interval: 30s

---
# tests/test_api.py - API Tests
import pytest
import numpy as np
from fastapi.testclient import TestClient
from src.api import app
import json

client = TestClient(app)

def test_health_check():
    """Test health endpoint"""
    response = client.get("/health")
    assert response.status_code == 200
    data = response.json()
    assert "status" in data
    assert "timestamp" in data
    assert data["status"] in ["healthy", "unhealthy"]

def test_metrics_endpoint():
    """Test metrics endpoint"""
    response = client.get("/metrics")
    assert response.status_code == 200

def create_test_signals():
    """Create test ECG and PPG signals"""
    # Simulate 30 seconds of data
    ecg_samples = np.sin(np.linspace(0, 30*2*np.pi, 30*360)).tolist()  # 30s at 360Hz
    ppg_samples = np.sin(np.linspace(0, 30*1*np.pi, 30*125)).tolist()  # 30s at 125Hz
    
    return {
        "patient_id": "test_patient_001",
        "ecg": {"samples": ecg_samples, "fs": 360},
        "ppg": {"samples": ppg_samples, "fs": 125},
        "metadata": {"age": 65, "gender": "M", "weight": 75}
    }

def test_predict_endpoint():
    """Test prediction endpoint with synthetic data"""
    test_data = create_test_signals()
    response = client.post("/predict", json=test_data)
    
    # Should work with synthetic data or fail gracefully if no model
    assert response.status_code in [200, 422, 500]
    
    if response.status_code == 200:
        data = response.json()
        assert "patient_id" in data
        assert "predictions" in data
        assert data["patient_id"] == test_data["patient_id"]

def test_predict_invalid_data():
    """Test prediction with invalid data"""
    invalid_data = {
        "patient_id": "test",
        "ecg": {"samples": [], "fs": 360},  # Empty samples
        "ppg": {"samples": [1, 2, 3], "fs": 125}
    }
    response = client.post("/predict", json=invalid_data)
    assert response.status_code == 422  # Validation error

def test_batch_predict():
    """Test batch prediction endpoint"""
    test_data = {
        "patients": [create_test_signals(), create_test_signals()]
    }
    test_data["patients"][1]["patient_id"] = "test_patient_002"
    
    response = client.post("/batch_predict", json=test_data)
    assert response.status_code in [200, 422, 500]

@pytest.mark.asyncio
async def test_explain_endpoint():
    """Test explanation endpoint"""
    test_data = create_test_signals()
    response = client.post("/explain", json=test_data)
    assert response.status_code in [200, 422, 500]

def test_report_endpoint():
    """Test report generation endpoint"""
    # First make a prediction to generate a report
    test_data = create_test_signals()
    pred_response = client.post("/predict", json=test_data)
    
    if pred_response.status_code == 200:
        # Try to get the report
        report_response = client.get(f"/report/{test_data['patient_id']}")
        assert report_response.status_code in [200, 404]  # 404 if report not found

---
# tests/test_models.py - Model Tests
import pytest
import torch
import numpy as np
from src.models import MultiModalCNNLSTM, BranchEncoder
from src.config import DEVICE

def test_branch_encoder():
    """Test BranchEncoder component"""
    model = BranchEncoder(in_channels=1, seq_len=3600, 
                         conv_filters=[32, 64], lstm_hidden=128)
    
    # Test input shape
    x = torch.randn(4, 1, 3600)  # batch_size=4, channels=1, seq_len=3600
    emb, seq_out = model(x)
    
    assert emb.shape == (4, 256)  # 128*2 (bidirectional LSTM)
    assert seq_out.shape[0] == 4
    assert seq_out.shape[2] == 256

def test_multimodal_model():
    """Test complete MultiModalCNNLSTM model"""
    model = MultiModalCNNLSTM(
        seq_len_ecg=3600, 
        seq_len_ppg=1250, 
        n_classes_arr=5, 
        stroke_output_dim=1
    )
    
    # Test forward pass
    ecg = torch.randn(2, 1, 3600)  # batch_size=2
    ppg = torch.randn(2, 1, 1250)
    
    outputs = model(ecg, ppg)
    
    assert "arr_logits" in outputs
    assert "stroke" in outputs
    assert "ecg_emb" in outputs
    assert "ppg_emb" in outputs
    assert "fused" in outputs
    
    assert outputs["arr_logits"].shape == (2, 5)  # 5 arrhythmia classes
    assert outputs["stroke"].shape == (2,)        # stroke risk score

def test_model_device_compatibility():
    """Test model works on available device"""
    model = MultiModalCNNLSTM(seq_len_ecg=360, seq_len_ppg=125, n_classes_arr=5)
    model = model.to(DEVICE)
    
    ecg = torch.randn(1, 1, 360).to(DEVICE)
    ppg = torch.randn(1, 1, 125).to(DEVICE)
    
    with torch.no_grad():
        outputs = model(ecg, ppg)
        assert outputs["arr_logits"].device.type == DEVICE.split(':')[0]

---
# .env - Environment Variables
# Database
DATABASE_URL=sqlite:///./ecg_ppg.db

# Redis (for caching)
REDIS_URL=redis://redis:6379/0

# Model paths
MODEL_PATH=./models/multimodal_best.pth
DATA_PATH=./data

# API settings
API_HOST=0.0.0.0
API_PORT=8081
DEBUG=false

# Monitoring
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000

# Security
SECRET_KEY=your-secret-key-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=structured

---
# docker-compose.prod.yml - Production Docker Setup
version: '3.8'

services:
  app:
    build: 
      context: .
      dockerfile: Dockerfile
      target: production
    restart: unless-stopped
    environment:
      - ENV=production
      - PYTHONPATH=/workspace
    volumes:
      - ./models:/workspace/models
      - ./data:/workspace/data
      - ./reports:/workspace/reports
      - ./logs:/workspace/logs
    expose:
      - "8081"
    depends_on:
      - redis
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
  
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl  # SSL certificates
      - ./reports:/workspace/reports:ro
    depends_on:
      - app
  
  redis:
    image: redis:alpine
    restart: unless-stopped
    expose:
      - "6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
  
  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
  
  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus

volumes:
  redis_data:
  prometheus_data:
  grafana_data: